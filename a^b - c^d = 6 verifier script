import time
import json
import os
from collections import Counter
from multiprocessing import Process, cpu_count, Manager
from github import Github

def get_range(var_name):
    while True:
        try:
            raw = input(f"Enter min and max for {var_name} (space-separated): ")
            min_val, max_val = map(int, raw.strip().split())
            if min_val > max_val:
                print(f"Error: {var_name} min > max.")
                continue
            return min_val, max_val
        except Exception:
            print("Invalid input. Please enter two integers separated by a space.")


def format_scientific(n: int) -> str:
    if n == 0:
        return "0"
    sign = "-" if n < 0 else ""
    s = str(abs(n))
    exp = len(s) - 1
    # take first two digits for mantissa
    if len(s) >= 2:
        mant = f"{s[0]}.{s[1]}"
    else:
        mant = f"{s[0]}.0"
    return f"{sign}{mant}e{exp}"


def worker(task_slice, queue, c_range, d_range):
    for a, b in task_slice:
        for c in range(*c_range):
            for d in range(*d_range):
                val = a**b - c**d
                error = 6 - val
                queue.put(({ 'a': a, 'b': b, 'c': c, 'd': d,
                             'error': format_scientific(error) }))
    queue.put(None)  # sentinel for this worker


def main():
    print("--- Diophantine solver + GitHub push ---")
    repo_input = input("Enter repository and file path (username/repo/path/to/file.json): ")
    parts = repo_input.strip().split('/', 2)
    if len(parts) < 3:
        print("Invalid input format. Use username/repo/path/to/file.json")
        return
    repo_name = f"{parts[0]}/{parts[1]}"
    path_in_repo = parts[2]
    token = input("Enter your GitHub personal access token: ")
    gh = Github(token)
    try:
        repo = gh.get_repo(repo_name)
    except Exception as e:
        print(f"Failed to access repository {repo_name}: {e}")
        return

    a_min, a_max = get_range('a')
    b_min, b_max = get_range('b')
    c_min, c_max = get_range('c')
    d_min, d_max = get_range('d')

    cores = cpu_count()
    print(f"Using {cores} cores.")

    tasks = [(a, b) for a in range(a_min, a_max+1) for b in range(b_min, b_max+1)]
    manager = Manager()
    queue = manager.Queue(maxsize=1000)

    # temp file for streaming checks
    temp_path = 'checks_temp.jsonl'
    if os.path.exists(temp_path): os.remove(temp_path)

    # start workers
    chunk = len(tasks) // cores + 1
    workers = []
    for i in range(cores):
        slice_ = tasks[i*chunk:(i+1)*chunk]
        p = Process(target=worker, args=(slice_, queue, (c_min, c_max+1), (d_min, d_max+1)))
        p.start()
        workers.append(p)

    # collect and write temp JSONL
    finished_workers = 0
    diagnostics = {
        'ranges': {'a': [a_min, a_max], 'b': [b_min, b_max], 'c': [c_min, c_max], 'd': [d_min, d_max]},
        'cores': cores,
        'computation_time_sec': None,
        'num_solutions': 0,
        'avg_error': None,
        'top_errors': None,
        'least_error_record': None
    }
    error_vals = []
    error_counter = Counter()
    least = None

    start = time.time()
    with open(temp_path, 'w') as tmpf:
        while finished_workers < cores:
            rec = queue.get()
            if rec is None:
                finished_workers += 1
                continue
            tmpf.write(json.dumps(rec) + '\n')
            # update diagnostics
            err_str = rec['error']
            # convert back to magnitude for counters? approximate: use first digit *10^exp
            # parsing mantissa and exponent
            if err_str != '0':
                mant, exp = err_str.split('e')
                val = float(mant) * (10 ** int(exp))
                error_vals.append(abs(val))
                error_counter[err_str] += 1
                # least error by magnitude
                if least is None or abs(val) < least[0]:
                    least = (abs(val), rec)
                if rec.get('solution'):
                    diagnostics['num_solutions'] += 1
            else:
                error_vals.append(0)
                error_counter['0'] += 1
                if least is None or 0 < least[0]:
                    least = (0, rec)
                if rec.get('solution'):
                    diagnostics['num_solutions'] += 1

    end = time.time()
    diagnostics['computation_time_sec'] = end - start
    diagnostics['avg_error'] = sum(error_vals) / len(error_vals) if error_vals else None
    diagnostics['top_errors'] = error_counter.most_common(5)
    diagnostics['least_error_record'] = least[1] if least else None

    # write final JSON
    output_filename = f"results_{a_min}-{a_max}_{b_min}-{b_max}_{c_min}-{c_max}_{d_min}-{d_max}.json"
    with open(temp_path, 'r') as tmpf, open(output_filename, 'w') as outf:
        outf.write('{' + json.dumps('diagnostics') + ':' )
        outf.write(json.dumps(diagnostics, indent=2))
        outf.write(',"checks":[\n')
        first = True
        for line in tmpf:
            if not first:
                outf.write(',\n')
            outf.write(line.strip())
            first = False
        outf.write('\n]}')

    # cleanup temp
    os.remove(temp_path)

    # push to GitHub
    with open(output_filename, 'r') as f:
        content = f.read()
    try:
        existing = repo.get_contents(path_in_repo)
        repo.update_file(path=path_in_repo,
                         message=f"Update {path_in_repo}",
                         content=content,
                         sha=existing.sha)
        print(f"Updated {path_in_repo}.")
    except:
        repo.create_file(path=path_in_repo,
                         message=f"Add {path_in_repo}",
                         content=content)
        print(f"Created {path_in_repo}.")

    print(f"Done. Output written to {output_filename} and pushed.")

if __name__ == '__main__':
    main()
