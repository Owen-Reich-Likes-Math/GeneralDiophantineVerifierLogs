import json
import math
import multiprocessing
import time
from github import Github
import base64
import sys

# Raise the max digits for int-to-str conversions
try:
    sys.set_int_max_str_digits(1000000)  # Raise as high as reasonably safe
except AttributeError:
    # For Python versions before 3.11
    pass

def check_diophantine(params):
    a, b, c, d = params
    try:
        val = pow(a, b) - pow(c, d)
    except OverflowError:
        val = float('inf')

    error = val - 6

    # Safely create error_exp
    try:
        error_exp = f"{float(error):.2e}"
    except (OverflowError, ValueError):
        try:
            error_exp = str(error)
        except ValueError:
            error_exp = "[unstringable error: value too large]"

    return {
        "a": a, "b": b, "c": c, "d": d,
        "value": val if val != float('inf') else "overflow",
        "error": error,
        "error_exp": error_exp
    }

def run_solver_and_push(repo, path_in_repo, a_min, a_max, b_min, b_max, c_min, c_max, d_min, d_max, cores):
    start_time = time.time()

    pool = multiprocessing.Pool(processes=cores)
    params = [(a, b, c, d)
              for a in range(a_min, a_max + 1)
              for b in range(b_min, b_max + 1)
              for c in range(c_min, c_max + 1)
              for d in range(d_min, d_max + 1)]

    results = pool.imap_unordered(check_diophantine, params, chunksize=1000)

    diagnostics = {
        "a_min": a_min, "a_max": a_max,
        "b_min": b_min, "b_max": b_max,
        "c_min": c_min, "c_max": c_max,
        "d_min": d_min, "d_max": d_max,
        "cores_used": cores,
        "start_time": start_time,
        "end_time": None,
        "elapsed_time_sec": None,
        "min_error": None,
        "solutions_found": [],
        "error_counts": {}
    }

    output_file = f"output_{a_min}_{a_max}_{b_min}_{b_max}_{c_min}_{c_max}_{d_min}_{d_max}.json"

    results_list = list(results)

    min_err = None
    error_counter = {}
    solutions = []

    for res in results_list:
        err = res['error']
        if min_err is None or abs(err) < abs(min_err):
            min_err = err
        if err == 0:
            solutions.append(res)
        err_key = res['error_exp']
        error_counter[err_key] = error_counter.get(err_key, 0) + 1

    diagnostics["end_time"] = time.time()
    diagnostics["elapsed_time_sec"] = diagnostics["end_time"] - diagnostics["start_time"]
    diagnostics["min_error"] = min_err
    diagnostics["solutions_found"] = solutions
    diagnostics["error_counts"] = error_counter

    full_output = {
        "diagnostics": diagnostics,
        "checks": results_list
    }

    content = json.dumps(full_output, indent=2)

    try:
        existing = repo.get_contents(path_in_repo)
        repo.update_file(path_in_repo, f"Update {path_in_repo}", content, existing.sha)
    except Exception:
        repo.create_file(path_in_repo, f"Add {path_in_repo}", content)

    print(f"Pushed results to GitHub at {path_in_repo}")
    print(f"Elapsed time: {diagnostics['elapsed_time_sec']:.2f} seconds")
    print(f"Minimum error found: {diagnostics['min_error']}")
    print(f"Number of solutions found: {len(solutions)}")
    if error_counter:
        most_freq_err = max(error_counter, key=error_counter.get)
        print(f"Most frequent error: {most_freq_err} with {error_counter[most_freq_err]} occurrences")
    else:
        print("No errors counted.")

def run_interval_loop_automatic(repo, base_path):
    start_min = int(input("Enter starting min value for all variables (e.g., 11): "))
    step = int(input("Enter step size (e.g., 2): "))
    absolute_max = int(input("Enter absolute max value to stop at (e.g., 10000): "))

    cores = multiprocessing.cpu_count()
    print(f"Using {cores} cores.")

    current_min = start_min
    while current_min <= absolute_max:
        current_max = min(current_min + step - 1, absolute_max)
        print(f"Running interval: {current_min} to {current_max} for a,b,c,d...")
        run_solver_and_push(
            repo=repo,
            path_in_repo=f"{base_path}_{current_min}_{current_max}.json",
            a_min=current_min, a_max=current_max,
            b_min=current_min, b_max=current_max,
            c_min=current_min, c_max=current_max,
            d_min=current_min, d_max=current_max,
            cores=cores
        )
        current_min = current_max + 1

def run_interval_loop_manual(repo, base_path):
    cores = multiprocessing.cpu_count()
    print(f"Using {cores} cores.")

    while True:
        print("Enter min and max for a (space-separated): ", end="")
        a_min, a_max = map(int, input().split())
        print("Enter min and max for b (space-separated): ", end="")
        b_min, b_max = map(int, input().split())
        print("Enter min and max for c (space-separated): ", end="")
        c_min, c_max = map(int, input().split())
        print("Enter min and max for d (space-separated): ", end="")
        d_min, d_max = map(int, input().split())

        run_solver_and_push(
            repo=repo,
            path_in_repo=f"{base_path}_{a_min}_{a_max}_{b_min}_{b_max}_{c_min}_{c_max}_{d_min}_{d_max}.json",
            a_min=a_min, a_max=a_max,
            b_min=b_min, b_max=b_max,
            c_min=c_min, c_max=c_max,
            d_min=d_min, d_max=d_max,
            cores=cores
        )

        cont = input("Run another interval? (y/n): ").strip().lower()
        if cont != 'y':
            break

def main():
    print("--- Diophantine solver + GitHub push ---")
    repo_path = input("Enter repository and file path (username/repo/path/to/file.json): ").strip()
    token = input("Enter your GitHub personal access token: ").strip()

    g = Github(token)
    try:
        user, repo_name, *repo_file_path = repo_path.split('/')
        repo_file_path = '/'.join(repo_file_path)
        repo = g.get_repo(f"{user}/{repo_name}")
    except Exception as e:
        print(f"Error accessing repository: {e}")
        return

    mode = input("Choose mode: manual intervals (m) or automatic intervals (a): ").strip().lower()

    if mode == 'a':
        run_interval_loop_automatic(repo, repo_file_path)
    else:
        run_interval_loop_manual(repo, repo_file_path)

if __name__ == "__main__":
    main()
